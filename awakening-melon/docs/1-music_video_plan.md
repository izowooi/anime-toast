# AI ë®¤ì§ë¹„ë””ì˜¤ ì œì‘ ì™„ë²½ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [í•„ìš”í•œ ë„êµ¬ ë° ì¤€ë¹„ì‚¬í•­](#í•„ìš”í•œ-ë„êµ¬-ë°-ì¤€ë¹„ì‚¬í•­)
3. [ë‹¨ê³„ë³„ ì œì‘ ì›Œí¬í”Œë¡œìš°](#ë‹¨ê³„ë³„-ì œì‘-ì›Œí¬í”Œë¡œìš°)
4. [ìë™í™” ìŠ¤í¬ë¦½íŠ¸](#ìë™í™”-ìŠ¤í¬ë¦½íŠ¸)
5. [í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸](#í’ˆì§ˆ-ì²´í¬ë¦¬ìŠ¤íŠ¸)
6. [ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](#ë¬¸ì œ-í•´ê²°-ê°€ì´ë“œ)

---

## í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
AIë¥¼ í™œìš©í•˜ì—¬ ì£¼ì œ ì„ ì •ë¶€í„° ìµœì¢… ì˜ìƒ í¸ì§‘ê¹Œì§€ ì™„ì„±ë„ ë†’ì€ ë®¤ì§ë¹„ë””ì˜¤ë¥¼ ì œì‘í•©ë‹ˆë‹¤.

### ì „ì²´ ì›Œí¬í”Œë¡œìš°
```
ì£¼ì œ ì„ ì • â†’ ê°€ì‚¬ ìƒì„± â†’ ìŒì•… ì œì‘ â†’ ì½˜í‹° ì‘ì„± 
â†’ í‚¤í”„ë ˆì„ ì´ë¯¸ì§€ ìƒì„± â†’ ë™ì˜ìƒ ë³€í™˜ â†’ ìµœì¢… í¸ì§‘
```

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- **ì´ˆê¸° ì œì‘**: 6-8ì‹œê°„
- **ìë™í™” êµ¬ì¶• í›„**: 3-4ì‹œê°„

---

## í•„ìš”í•œ ë„êµ¬ ë° ì¤€ë¹„ì‚¬í•­

### 1. AI ì„œë¹„ìŠ¤ (ëª¨ë‘ êµ¬ë… ì¤‘)
- **Suno AI**: ìŒì•… ìƒì„±
- **Nijijourney**: ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ìƒì„±
- **Gemini**: ê°€ì‚¬ ë° ì½˜í‹° ìƒì„±
- **Veo 3**: ì´ë¯¸ì§€â†’ë™ì˜ìƒ ë³€í™˜

### 2. API ë° ê°œë°œ ë„êµ¬
```bash
# í•„ìš”í•œ Python íŒ¨í‚¤ì§€
pip install anthropic replicate requests aiohttp ffmpeg-python librosa

# Node.js íŒ¨í‚¤ì§€ (ì„ íƒì‚¬í•­)
npm install @anthropic-ai/sdk openai replicate
```

### 3. í¸ì§‘ ì†Œí”„íŠ¸ì›¨ì–´
- **DaVinci Resolve** (ë¬´ë£Œ) ë˜ëŠ” **Adobe Premiere Pro**
- **FFmpeg** (ì»¤ë§¨ë“œë¼ì¸ ì˜ìƒ ì²˜ë¦¬)

### 4. í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡°
```
music-video-project/
â”œâ”€â”€ 01_theme/              # ì£¼ì œ ë° ê¸°íš
â”œâ”€â”€ 02_lyrics/             # ìƒì„±ëœ ê°€ì‚¬
â”œâ”€â”€ 03_music/              # Suno ìƒì„± ìŒì•…
â”œâ”€â”€ 04_storyboard/         # ì½˜í‹° JSON íŒŒì¼
â”œâ”€â”€ 05_images/             # Nijijourney ì´ë¯¸ì§€
â”œâ”€â”€ 06_videos/             # ê°œë³„ ì˜ìƒ í´ë¦½
â”œâ”€â”€ 07_final/              # ìµœì¢… ê²°ê³¼ë¬¼
â””â”€â”€ scripts/               # ìë™í™” ìŠ¤í¬ë¦½íŠ¸
```

---

## ë‹¨ê³„ë³„ ì œì‘ ì›Œí¬í”Œë¡œìš°

## STEP 1: ì£¼ì œ ì„ ì • ë° ê¸°íš

### 1-1. ì£¼ì œ ê²°ì •
ë®¤ì§ë¹„ë””ì˜¤ì˜ í•µì‹¬ ë©”ì‹œì§€ì™€ ë¶„ìœ„ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ ì£¼ì œ**:
- "ê¿ˆì„ í–¥í•´ ë‚ ì•„ê°€ëŠ” ì†Œë…€"
- "ì‚¬ì´ë²„í‘í¬ ë„ì‹œì˜ ë°¤"
- "ì²«ì‚¬ë‘ì˜ ì¶”ì–µ"

### 1-2. ë¬´ë“œë³´ë“œ ì‘ì„±
ì£¼ì œì— ë§ëŠ” ì‹œê°ì  ë ˆí¼ëŸ°ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```markdown
# ë¬´ë“œë³´ë“œ ì˜ˆì‹œ
## ìƒ‰ê°
- ì£¼ì¡°ìƒ‰: íŒŒìŠ¤í…” í•‘í¬, í•˜ëŠ˜ìƒ‰
- ë³´ì¡°ìƒ‰: ê³¨ë“œ, í™”ì´íŠ¸

## ë¶„ìœ„ê¸°
- ë”°ëœ»í•˜ê³  ëª½í™˜ì 
- Studio Ghibli ìŠ¤íƒ€ì¼
- ë¶€ë“œëŸ¬ìš´ ë¹›ê³¼ ê·¸ë¦¼ì

## ë ˆí¼ëŸ°ìŠ¤
- ì„¼ê³¼ ì¹˜íˆë¡œì˜ í–‰ë°©ë¶ˆëª… (ë°°ê²½)
- ë„ˆì˜ ì´ë¦„ì€ (ìƒ‰ê°)
```

**ğŸ’¡ TIP**: Pinterestë‚˜ ArtStationì—ì„œ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ 5-10ì¥ ì €ì¥í•˜ì„¸ìš”.

---

## STEP 2: ê°€ì‚¬ ìƒì„± (Gemini)

### 2-1. Geminië¡œ ê°€ì‚¬ ì‘ì„±

**í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**:
```
ë„ˆëŠ” ì „ë¬¸ ì‘ì‚¬ê°€ì•¼. ë‹¤ìŒ ì£¼ì œë¡œ ë®¤ì§ë¹„ë””ì˜¤ìš© ê°€ì‚¬ë¥¼ ì‘ì„±í•´ì¤˜.

ì£¼ì œ: [ë‹¹ì‹ ì˜ ì£¼ì œ]
ì¥ë¥´: [íŒ/ë°œë¼ë“œ/ë¡ ë“±]
ë¶„ìœ„ê¸°: [í¬ë§ì /ìŠ¬í”ˆ/ì—­ë™ì  ë“±]
ê¸¸ì´: 2ë¶„ 30ì´ˆ ë‚´ì™¸ (Verse 2ê°œ + Chorus 2ê°œ + Bridge)

ì¡°ê±´:
- ê° ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì¤˜ ([Verse 1], [Chorus] ë“±)
- Suno AIì— ì…ë ¥í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ
- ê°ì • ì „í™˜ì´ ìì—°ìŠ¤ëŸ¬ì›Œì•¼ í•¨
- ì‹œê°ì  ì´ë¯¸ì§€ë¥¼ ë– ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í‘œí˜„ ì‚¬ìš©
```

### 2-2. ê°€ì‚¬ êµ¬ì¡° ê²€ì¦

ìƒì„±ëœ ê°€ì‚¬ê°€ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ”ì§€ í™•ì¸:
```
[Intro] (5-10ì´ˆ)
[Verse 1] (20-30ì´ˆ)
[Chorus] (20-30ì´ˆ)
[Verse 2] (20-30ì´ˆ)
[Chorus] (20-30ì´ˆ)
[Bridge] (15-20ì´ˆ)
[Outro] (10-15ì´ˆ)
```

**ğŸ’¡ TIP**: ê° ì„¹ì…˜ì˜ ì˜ˆìƒ ì‹œê°„ì„ ë©”ëª¨í•´ë‘ë©´ ì½˜í‹° ì‘ì„± ì‹œ ìœ ìš©í•©ë‹ˆë‹¤.

---

## STEP 3: ìŒì•… ìƒì„± (Suno AI)

### 3-1. Sunoì—ì„œ 3-5ê³¡ ìƒì„±

**Suno ì…ë ¥ ë°©ë²•**:
1. Suno AI ì›¹ì‚¬ì´íŠ¸ ì ‘ì†
2. Custom Mode ì„ íƒ
3. ê°€ì‚¬ ë¶™ì—¬ë„£ê¸°
4. Style of Music ì…ë ¥ ì˜ˆì‹œ:
   ```
   Anime opening, J-pop, uplifting, female vocals, 
   orchestral elements, 130 BPM
   ```

**ìƒì„± ì „ëµ**:
- ê°™ì€ ê°€ì‚¬ë¡œ 3-5ê°œ ë²„ì „ ìƒì„±
- ë³´ì»¬ ìŠ¤íƒ€ì¼(ë‚¨ì„±/ì—¬ì„±/í˜¼ì„±)ì„ ë‹¤ë¥´ê²Œ ì‹œë„
- BPMì„ ì¡°ì •í•´ê°€ë©° í…ŒìŠ¤íŠ¸ (ëŠë¦° ê³¡ vs ë¹ ë¥¸ ê³¡)

### 3-2. ìµœì ì˜ ê³¡ ì„ ì • ê¸°ì¤€

| í‰ê°€ í•­ëª© | ì²´í¬ í¬ì¸íŠ¸ |
|----------|------------|
| **ê°€ì‚¬ ì „ë‹¬ë ¥** | ë°œìŒì´ ëª…í™•í•œê°€? |
| **ê°ì • í‘œí˜„** | ê°€ì‚¬ì˜ ê°ì •ì´ ì˜ ì „ë‹¬ë˜ëŠ”ê°€? |
| **ì˜ìƒ í¸ì§‘ ìš©ì´ì„±** | ëª…í™•í•œ ë¹„íŠ¸ì™€ ì„¹ì…˜ êµ¬ë¶„ì´ ìˆëŠ”ê°€? |
| **ì „ì²´ íë¦„** | ì§€ë£¨í•œ êµ¬ê°„ ì—†ì´ ëª°ì…ë˜ëŠ”ê°€? |

### 3-3. ì„ ì •ê³¡ ë¶„ì„

ì„ íƒí•œ ê³¡ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:

```python
import librosa
import numpy as np

def analyze_song(audio_path):
    """
    ë…¸ë˜ì˜ BPM, ë¹„íŠ¸ íƒ€ì´ë°, ì„¹ì…˜ì„ ë¶„ì„
    """
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_path)
    
    # BPM ì¶”ì¶œ
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
    beat_times = librosa.frames_to_time(beats, sr=sr)
    
    # êµ¬ì¡° ë¶„ì„ (Verse, Chorus ì¶”ì •)
    mfcc = librosa.feature.mfcc(y=y, sr=sr)
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    
    return {
        'bpm': tempo,
        'beat_times': beat_times.tolist(),
        'duration': librosa.get_duration(y=y, sr=sr)
    }

# ì‚¬ìš© ì˜ˆì‹œ
song_data = analyze_song('03_music/selected_song.mp3')
print(f"BPM: {song_data['bpm']:.1f}")
print(f"ì´ ê¸¸ì´: {song_data['duration']:.1f}ì´ˆ")
```

**ğŸ’¡ TIP**: BPMì´ ë†’ì„ìˆ˜ë¡ ë¹ ë¥¸ ì»· ì „í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤. BPM 120 ì´ìƒì´ë©´ 3-5ì´ˆ ì»·, 90 ì´í•˜ë©´ 5-8ì´ˆ ì»· ê¶Œì¥.

---

## STEP 4: ì½˜í‹° ì‘ì„± (Gemini)

### 4-1. êµ¬ì¡°í™”ëœ ì½˜í‹° ìŠ¤í‚¤ë§ˆ ì •ì˜

```python
from typing import List, Literal
from pydantic import BaseModel

class Shot(BaseModel):
    """ê°œë³„ ì»·(ì”¬) ì •ì˜"""
    shot_number: int                                    # ì»· ë²ˆí˜¸
    timestamp_start: float                              # ì‹œì‘ ì‹œê°„ (ì´ˆ)
    timestamp_end: float                                # ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
    lyrics_line: str                                    # í•´ë‹¹ êµ¬ê°„ ê°€ì‚¬
    scene_description: str                              # ì”¬ ì„¤ëª…
    shot_type: Literal["CU", "MS", "LS", "ECU"]        # ìƒ· íƒ€ì…
    camera_movement: Literal["static", "pan", "zoom", "dolly"]
    character_action: str                               # ìºë¦­í„° ë™ì‘
    mood: str                                           # ë¶„ìœ„ê¸° (bright/dark/dramatic)
    visual_style: str                                   # ì‹œê°ì  ìŠ¤íƒ€ì¼ ë””í…Œì¼
    
class Storyboard(BaseModel):
    """ì „ì²´ ì½˜í‹°"""
    title: str
    total_duration: float
    shots: List[Shot]
```

**ìš©ì–´ ì„¤ëª…**:
- **CU (Close-Up)**: ì–¼êµ´ í´ë¡œì¦ˆì—…
- **MS (Medium Shot)**: ìƒë°˜ì‹ 
- **LS (Long Shot)**: ì „ì‹  ë˜ëŠ” ë„“ì€ ë°°ê²½
- **ECU (Extreme Close-Up)**: ëˆˆ, ì† ë“± ê·¹ë‹¨ì  í´ë¡œì¦ˆì—…

### 4-2. Geminië¡œ ì½˜í‹° ìƒì„±

**í”„ë¡¬í”„íŠ¸**:
```python
prompt = f"""
ë‹¹ì‹ ì€ ì• ë‹ˆë©”ì´ì…˜ ë®¤ì§ë¹„ë””ì˜¤ ê°ë…ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê°€ì‚¬ì™€ ë…¸ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì½˜í‹°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

# ë…¸ë˜ ì •ë³´
- ì œëª©: {song_title}
- BPM: {bpm}
- ì´ ê¸¸ì´: {duration}ì´ˆ
- ì¥ë¥´: {genre}

# ê°€ì‚¬
{lyrics}

# ì‹œê°ì  ìŠ¤íƒ€ì¼
{visual_references}

# ìš”êµ¬ì‚¬í•­
1. 30-50ê°œì˜ ì»·ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”
2. ê° ì»·ì€ 3-8ì´ˆ ê¸¸ì´ë¡œ (BPMì— ë”°ë¼ ì¡°ì •)
3. ë¹„íŠ¸ê°€ ê°•í•œ êµ¬ê°„(Chorus)ì—ëŠ” ì—­ë™ì ì¸ ìƒ· ë°°ì¹˜
4. ê°€ì‚¬ì˜ ê°ì • ë³€í™”ì— ë”°ë¼ shot_typeê³¼ mood ë³€ê²½
5. ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•´ ê°™ì€ ì£¼ì¸ê³µ ì„¤ì • ìœ ì§€

# ì¶œë ¥ í˜•ì‹
JSON í˜•ì‹ìœ¼ë¡œ ìœ„ì˜ Storyboard ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¼ ì¶œë ¥í•˜ì„¸ìš”.
"""

import anthropic

client = anthropic.Anthropic(api_key="YOUR_API_KEY")

response = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=8000,
    messages=[{
        "role": "user",
        "content": prompt
    }]
)

# JSON íŒŒì‹±
import json
storyboard_json = json.loads(response.content[0].text)
```

### 4-3. ì½˜í‹° ê²€ì¦ ë° ì¡°ì •

ìƒì„±ëœ ì½˜í‹°ë¥¼ ê²€í† í•©ë‹ˆë‹¤:

```python
def validate_storyboard(storyboard: Storyboard, song_duration: float):
    """
    ì½˜í‹°ì˜ íƒ€ì´ë°ì´ ë…¸ë˜ ê¸¸ì´ì™€ ë§ëŠ”ì§€ ê²€ì¦
    """
    issues = []
    
    # 1. ì´ ê¸¸ì´ ì²´í¬
    last_shot_end = storyboard.shots[-1].timestamp_end
    if abs(last_shot_end - song_duration) > 2.0:
        issues.append(f"ì½˜í‹° ê¸¸ì´({last_shot_end}ì´ˆ)ê°€ ë…¸ë˜ ê¸¸ì´({song_duration}ì´ˆ)ì™€ {abs(last_shot_end - song_duration):.1f}ì´ˆ ì°¨ì´ë‚¨")
    
    # 2. ì»· ê°„ ê³µë°± ì²´í¬
    for i in range(len(storyboard.shots) - 1):
        current_end = storyboard.shots[i].timestamp_end
        next_start = storyboard.shots[i + 1].timestamp_start
        if next_start - current_end > 0.1:
            issues.append(f"ì»· {i+1}ê³¼ {i+2} ì‚¬ì´ ê³µë°± {next_start - current_end:.2f}ì´ˆ")
    
    # 3. ì»· ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì»·)
    for shot in storyboard.shots:
        duration = shot.timestamp_end - shot.timestamp_start
        if duration < 2.0:
            issues.append(f"ì»· {shot.shot_number}: ë„ˆë¬´ ì§§ìŒ ({duration:.1f}ì´ˆ)")
        elif duration > 10.0:
            issues.append(f"ì»· {shot.shot_number}: ë„ˆë¬´ ê¹€ ({duration:.1f}ì´ˆ)")
    
    return issues

# ê²€ì¦ ì‹¤í–‰
issues = validate_storyboard(storyboard, song_data['duration'])
if issues:
    print("âš ï¸ ì½˜í‹° ì¡°ì • í•„ìš”:")
    for issue in issues:
        print(f"  - {issue}")
```

**ğŸ’¡ TIP**: ë¬¸ì œê°€ ë°œê²¬ë˜ë©´ Geminiì—ê²Œ í”¼ë“œë°±ì„ ì£¼ê³  ì¬ìƒì„±ì„ ìš”ì²­í•˜ì„¸ìš”.

---

## STEP 5: ì´ë¯¸ì§€ ìƒì„± (Nijijourney)

### 5-1. Character Reference ì´ë¯¸ì§€ ë¨¼ì € ìƒì„±

ì¼ê´€ëœ ìºë¦­í„°ë¥¼ ìœ„í•´ **ì²« ë²ˆì§¸ ì´ë¯¸ì§€ê°€ ê°€ì¥ ì¤‘ìš”**í•©ë‹ˆë‹¤.

**ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ**:
```
A young girl with long flowing brown hair, bright blue eyes, 
wearing a white summer dress, standing in a flower field, 
anime style, Studio Ghibli inspired, soft pastel colors, 
warm lighting, gentle smile, age 16, full body shot
--ar 16:9 --niji 6 --style expressive
```

**ìƒì„± ì ˆì°¨**:
1. Nijijourneyì—ì„œ ìœ„ í”„ë¡¬í”„íŠ¸ë¡œ 4ê°œ ìƒì„±
2. ê°€ì¥ ë§ˆìŒì— ë“œëŠ” ì´ë¯¸ì§€ ì„ íƒí•˜ì—¬ Upscale
3. í•´ë‹¹ ì´ë¯¸ì§€ URL ë³µì‚¬ (ì´í›„ ëª¨ë“  ì´ë¯¸ì§€ì— ì‚¬ìš©)

### 5-2. ì½˜í‹° ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±

```python
def generate_niji_prompt(shot: Shot, character_ref_url: str, style_ref_url: str) -> str:
    """
    ì½˜í‹°ì˜ ê° ìƒ·ì„ Nijijourney í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
    """
    # Shot typeë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
    shot_descriptions = {
        "CU": "close-up portrait shot, focus on face",
        "MS": "medium shot, waist up",
        "LS": "wide shot, full body with background",
        "ECU": "extreme close-up, eyes or hands detail"
    }
    
    # Camera movement í‘œí˜„
    camera_descriptions = {
        "static": "static camera",
        "pan": "dynamic pan movement",
        "zoom": "cinematic zoom effect",
        "dolly": "dolly tracking shot"
    }
    
    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
    prompt = f"""
{shot.scene_description}, {shot.character_action},
{shot_descriptions[shot.shot_type]},
{camera_descriptions[shot.camera_movement]},
{shot.visual_style}, {shot.mood} mood,
anime style, Studio Ghibli inspired, soft color palette,
volumetric lighting, detailed background,
--cref {character_ref_url} --cw 100
--sref {style_ref_url} --sw 50
--ar 16:9 --niji 6 --style expressive
""".strip()
    
    return prompt

# ì „ì²´ ì½˜í‹°ì— ëŒ€í•´ í”„ë¡¬í”„íŠ¸ ìƒì„±
character_ref = "https://s.mj.run/YOUR_CHARACTER_IMAGE_ID"
style_ref = "https://s.mj.run/YOUR_STYLE_IMAGE_ID"

prompts = []
for shot in storyboard.shots:
    prompt = generate_niji_prompt(shot, character_ref, style_ref)
    prompts.append({
        'shot_number': shot.shot_number,
        'prompt': prompt,
        'timestamp': shot.timestamp_start
    })

# í”„ë¡¬í”„íŠ¸ ì €ì¥
with open('04_storyboard/niji_prompts.json', 'w', encoding='utf-8') as f:
    json.dump(prompts, f, indent=2, ensure_ascii=False)
```

### 5-3. Nijijourney ì´ë¯¸ì§€ ìƒì„± í”„ë¡œì„¸ìŠ¤

**ìˆ˜ë™ ì›Œí¬í”Œë¡œìš°** (NijijourneyëŠ” ê³µì‹ API ì—†ìŒ):
1. Discord Nijijourney ì±„ë„ ì ‘ì†
2. `/imagine` ëª…ë ¹ì–´ ì‚¬ìš©
3. ê° í”„ë¡¬í”„íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥
4. ìƒì„±ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì´ë¦„ ì •ë¦¬

**íŒŒì¼ëª… ê·œì¹™**:
```
shot_001_CU_girl_smiling.png
shot_002_MS_girl_running.png
shot_003_LS_flower_field.png
...
```

**ë°˜ìë™ ì›Œí¬í”Œë¡œìš°** (Midjourney API ì„œë¹„ìŠ¤ ì´ìš©):
```python
# ë¹„ê³µì‹ API ì‚¬ìš© ì˜ˆì‹œ (UseAPI, GoAPI ë“±)
import requests

def generate_niji_image(prompt: str, shot_number: int):
    """
    ë¹„ê³µì‹ APIë¥¼ í†µí•œ Nijijourney ì´ë¯¸ì§€ ìƒì„±
    """
    response = requests.post(
        "https://api.useapi.net/v2/jobs/imagine",
        headers={"Authorization": f"Bearer {API_KEY}"},
        json={
            "prompt": prompt,
            "webhookOverride": "YOUR_WEBHOOK_URL"
        }
    )
    
    job_id = response.json()['jobid']
    
    # ì´ë¯¸ì§€ ìƒì„± ëŒ€ê¸° (ì•½ 60ì´ˆ)
    while True:
        status = requests.get(
            f"https://api.useapi.net/v2/jobs/{job_id}",
            headers={"Authorization": f"Bearer {API_KEY}"}
        )
        
        if status.json()['status'] == 'completed':
            image_url = status.json()['imageURL']
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            download_image(image_url, f"05_images/shot_{shot_number:03d}.png")
            break
        
        time.sleep(10)
```

**ğŸ’¡ TIP**: 
- í•œ ë²ˆì— 5-10ê°œì”© ìƒì„±í•˜ê³  ì¤‘ê°„ ê²€í† 
- ìºë¦­í„° ì¼ê´€ì„±ì´ ë–¨ì–´ì§€ëŠ” ì´ë¯¸ì§€ëŠ” ì¬ìƒì„±
- `--cw` (character weight) ê°’ì„ 100ìœ¼ë¡œ ìµœëŒ€í™”

### 5-4. ì¼ê´€ì„± ì²´í¬ ë° ì¬ìƒì„±

```python
def check_character_consistency(image_folder: str):
    """
    ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì˜ ì¼ê´€ì„±ì„ ì‹œê°ì ìœ¼ë¡œ ì²´í¬
    (ìˆ˜ë™ ê²€í† ìš© HTML ë·°ì–´ ìƒì„±)
    """
    import glob
    from pathlib import Path
    
    images = sorted(glob.glob(f"{image_folder}/shot_*.png"))
    
    html = """
    <html>
    <head><title>Character Consistency Check</title></head>
    <body>
    <h1>ìºë¦­í„° ì¼ê´€ì„± ì²´í¬</h1>
    <p>ë¬¸ì œê°€ ìˆëŠ” ì´ë¯¸ì§€ëŠ” ì²´í¬í•˜ì„¸ìš”</p>
    """
    
    for img in images:
        shot_num = Path(img).stem.split('_')[1]
        html += f"""
        <div style="display:inline-block; margin:10px; border:2px solid #ccc;">
            <img src="{img}" width="400"><br>
            <label><input type="checkbox" name="regenrate" value="{shot_num}">
            Shot {shot_num} ì¬ìƒì„± í•„ìš”</label>
        </div>
        """
    
    html += "</body></html>"
    
    with open('05_images/consistency_check.html', 'w') as f:
        f.write(html)
    
    print("âœ… 05_images/consistency_check.html íŒŒì¼ì„ ë¸Œë¼ìš°ì €ë¡œ ì—´ì–´ì„œ ì²´í¬í•˜ì„¸ìš”")
```

---

## STEP 6: ë™ì˜ìƒ ë³€í™˜

### 6-1. ë„êµ¬ ì„ íƒ ê°€ì´ë“œ

| ë„êµ¬ | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |
|------|------|------|----------|
| **Veo 3** | ìµœê³  í’ˆì§ˆ, ê¸´ ì˜ìƒ(60ì´ˆ) | API ì—†ìŒ, ìˆ˜ë™ ì‘ì—… | í•µì‹¬ ì”¬ë§Œ ì„ ë³„ |
| **Replicate API** | ìë™í™” ê°€ëŠ¥, ë‹¤ì–‘í•œ ëª¨ë¸ | í’ˆì§ˆ í¸ì°¨ | ëŒ€ëŸ‰ ë³€í™˜ |
| **ComfyUI** | ì„¸ë°€í•œ ì œì–´, ë¡œì»¬ ì²˜ë¦¬ | ë³µì¡í•œ ì„¤ì • | ê³ ê¸‰ ì‚¬ìš©ì |

### 6-2. Veo 3 ì‚¬ìš© (ìˆ˜ë™)

**í”„ë¡œì„¸ìŠ¤**:
1. Google AI Studio ì ‘ì†
2. Veo 3 ì„ íƒ
3. ì´ë¯¸ì§€ ì—…ë¡œë“œ
4. í”„ë¡¬í”„íŠ¸ ì…ë ¥:
   ```
   Animate this image with smooth camera movement. 
   The character should [ìºë¦­í„° ë™ì‘], 
   duration: [ì½˜í‹° duration]ì´ˆ
   ```
5. ìƒì„±ëœ ì˜ìƒ ë‹¤ìš´ë¡œë“œ

**ì–¸ì œ ì‚¬ìš©í•˜ë‚˜**:
- ì¤‘ìš”í•œ í´ë¼ì´ë§¥ìŠ¤ ì”¬ (Chorus, Bridge)
- ë³µì¡í•œ ì¹´ë©”ë¼ ì›Œí¬ê°€ í•„ìš”í•œ ì¥ë©´
- ì´ ì»·ì˜ 20-30%ë§Œ Veo 3ë¡œ ì²˜ë¦¬í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” Replicate ê¶Œì¥

### 6-3. Replicate API ì‚¬ìš© (ìë™)

```python
import replicate
import time

def image_to_video_replicate(
    image_path: str, 
    output_path: str,
    motion_prompt: str,
    duration_seconds: int = 4
):
    """
    Replicateì˜ Stable Video Diffusion ë˜ëŠ” Animate Diff ì‚¬ìš©
    """
    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
    import base64
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()
    
    # Replicate API í˜¸ì¶œ
    output = replicate.run(
        "stability-ai/stable-video-diffusion:3f0457e4619daac51203dedb472816fd4af51f3149fa7a9e0b5ffcf1b8172438",
        input={
            "image": f"data:image/png;base64,{image_data}",
            "num_frames": duration_seconds * 24,  # 24fps
            "motion_bucket_id": 127,  # 127 = ì¤‘ê°„ ëª¨ì…˜
            "fps": 24,
            "cond_aug": 0.02
        }
    )
    
    # ê²°ê³¼ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ
    video_url = output  # ReplicateëŠ” URL ë°˜í™˜
    download_video(video_url, output_path)
    
    return output_path

# ì „ì²´ ì½˜í‹°ì— ëŒ€í•´ ë³€í™˜
for shot in storyboard.shots:
    shot_num = shot.shot_number
    image_path = f"05_images/shot_{shot_num:03d}.png"
    output_path = f"06_videos/clip_{shot_num:03d}.mp4"
    
    duration = shot.timestamp_end - shot.timestamp_start
    motion_prompt = shot.character_action
    
    print(f"Converting shot {shot_num}...")
    image_to_video_replicate(
        image_path, 
        output_path, 
        motion_prompt,
        int(duration)
    )
    
    # API Rate Limit ê³ ë ¤
    time.sleep(2)
```

### 6-4. ComfyUI ì›Œí¬í”Œë¡œìš° (ì„ íƒì‚¬í•­)

**í•„ìš” ì¡°ê±´**:
- NVIDIA GPU (ìµœì†Œ RTX 3060 12GB)
- ComfyUI ì„¤ì¹˜
- AnimateDiff + ControlNet ëª¨ë¸

**ì¥ì **:
- í”„ë ˆì„ë³„ ì •ë°€ ì œì–´
- ë¡œì»¬ ì²˜ë¦¬ë¡œ ë¹„ìš© ì ˆê°
- ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥

**ì›Œí¬í”Œë¡œìš° JSON ì˜ˆì‹œ**ëŠ” ComfyUI ì»¤ë®¤ë‹ˆí‹°ì—ì„œ "AnimateDiff workflow" ê²€ìƒ‰.

---

## STEP 7: ìµœì¢… í¸ì§‘

### 7-1. FFmpegë¡œ í´ë¦½ ê²°í•© (ê¸°ë³¸ ë²„ì „)

```python
import subprocess

def create_video_concat_file(storyboard: Storyboard, output_path: str):
    """
    FFmpeg concatì„ ìœ„í•œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    """
    with open(output_path, 'w') as f:
        for shot in storyboard.shots:
            shot_num = shot.shot_number
            duration = shot.timestamp_end - shot.timestamp_start
            f.write(f"file '06_videos/clip_{shot_num:03d}.mp4'\n")
            f.write(f"duration {duration}\n")

# Concat íŒŒì¼ ìƒì„±
create_video_concat_file(storyboard, 'concat_list.txt')

# FFmpegë¡œ ê²°í•©
subprocess.run([
    'ffmpeg',
    '-f', 'concat',
    '-safe', '0',
    '-i', 'concat_list.txt',
    '-i', '03_music/selected_song.mp3',  # ì˜¤ë””ì˜¤ ì¶”ê°€
    '-c:v', 'libx264',
    '-c:a', 'aac',
    '-shortest',  # ì§§ì€ ìª½ì— ë§ì¶¤
    '07_final/music_video_draft.mp4'
])
```

### 7-2. DaVinci Resolve í¸ì§‘ (ê¶Œì¥)

**ì™œ DaVinciì¸ê°€**:
- ë¬´ë£Œ ë²„ì „ìœ¼ë¡œ ì¶©ë¶„
- ì •ë°€í•œ íƒ€ì´ë° ì¡°ì •
- ìƒ‰ë³´ì • ë° ì´í™íŠ¸
- ìë§‰ ì¶”ê°€ ê°€ëŠ¥

**í¸ì§‘ í”„ë¡œì„¸ìŠ¤**:
1. **í”„ë¡œì íŠ¸ ìƒì„±**
   - 24fps, 1920x1080 (ë˜ëŠ” 3840x2160)
   
2. **ë¯¸ë””ì–´ í’€ì— Import**
   - `06_videos/` í´ë” ì „ì²´ import
   - ìŒì•… íŒŒì¼ import

3. **íƒ€ì„ë¼ì¸ ë°°ì¹˜**
   ```
   Track 1: ì˜¤ë””ì˜¤ (Suno ìŒì•…)
   Track 2: ë¹„ë””ì˜¤ í´ë¦½ë“¤
   Track 3: íŠ¸ëœì§€ì…˜ íš¨ê³¼
   Track 4: ìë§‰ (ì„ íƒ)
   ```

4. **í´ë¦½ ê¸¸ì´ ì¡°ì •**
   - ì½˜í‹°ì˜ `timestamp_start`, `timestamp_end`ì— ë§ì¶° ì •ë ¬
   - Ripple Edit ëª¨ë“œ ì‚¬ìš© ê¶Œì¥

5. **íŠ¸ëœì§€ì…˜ ì¶”ê°€**
   - Chorus êµ¬ê°„: Cross Dissolve (0.5ì´ˆ)
   - Verse êµ¬ê°„: Cut (íŠ¸ëœì§€ì…˜ ì—†ìŒ)
   - Bridge: Dip to White (ê·¹ì  ì „í™˜)

6. **ìƒ‰ë³´ì •** (Color íƒ­)
   - ì „ì²´ í´ë¦½ì— í†µì¼ëœ LUT ì ìš©
   - ë°ê¸°/ëŒ€ë¹„ ì¡°ì •
   - ìƒ‰ì˜¨ë„ ë§ì¶¤

7. **Export**
   - Format: MP4
   - Codec: H.264
   - Resolution: 1080p
   - Bitrate: 10 Mbps

### 7-3. íƒ€ì´ë° ë¯¸ì„¸ ì¡°ì • ìŠ¤í¬ë¦½íŠ¸

```python
def adjust_clip_timing(video_path: str, start_time: float, end_time: float, output_path: str):
    """
    ê°œë³„ í´ë¦½ì˜ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ì„ ì •ë°€í•˜ê²Œ ì¡°ì •
    """
    duration = end_time - start_time
    
    subprocess.run([
        'ffmpeg',
        '-i', video_path,
        '-ss', str(start_time),
        '-t', str(duration),
        '-c:v', 'libx264',
        '-preset', 'fast',
        output_path
    ])

# ì˜ˆ: í´ë¦½ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ íŠ¸ë¦¬ë° í•„ìš”í•œ ê²½ìš°
adjust_clip_timing(
    '06_videos/clip_015.mp4',
    start_time=0.5,  # ì• 0.5ì´ˆ ì œê±°
    end_time=4.0,    # 4ì´ˆê¹Œì§€ë§Œ ì‚¬ìš©
    output_path='06_videos/clip_015_trimmed.mp4'
)
```

### 7-4. í’ˆì§ˆ í–¥ìƒ ì˜µì…˜

**Upscaling** (1080p â†’ 4K):
```bash
ffmpeg -i music_video_draft.mp4 \
  -vf "scale=3840:2160:flags=lanczos" \
  -c:v libx265 -preset slow -crf 18 \
  music_video_4k.mp4
```

**í”„ë ˆì„ ë³´ê°„** (24fps â†’ 60fps):
```bash
# RIFE ëª¨ë¸ ì‚¬ìš© (ë³„ë„ ì„¤ì¹˜ í•„ìš”)
python inference_video.py \
  --video music_video_draft.mp4 \
  --output music_video_60fps.mp4 \
  --fps 60
```

---

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸

```python
import asyncio
import os
from pathlib import Path

class MusicVideoPipeline:
    """
    ë®¤ì§ë¹„ë””ì˜¤ ì œì‘ ìë™í™” íŒŒì´í”„ë¼ì¸
    """
    def __init__(self, project_name: str):
        self.project_name = project_name
        self.base_dir = Path(f"music-video-project/{project_name}")
        self._create_folders()
        
    def _create_folders(self):
        """í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±"""
        folders = [
            '01_theme', '02_lyrics', '03_music', '04_storyboard',
            '05_images', '06_videos', '07_final', 'scripts'
        ]
        for folder in folders:
            (self.base_dir / folder).mkdir(parents=True, exist_ok=True)
    
    async def step1_generate_lyrics(self, theme: str, genre: str, mood: str):
        """ê°€ì‚¬ ìƒì„±"""
        print("ğŸ“ STEP 1: ê°€ì‚¬ ìƒì„± ì¤‘...")
        
        prompt = f"""
        ë„ˆëŠ” ì „ë¬¸ ì‘ì‚¬ê°€ì•¼. ë‹¤ìŒ ì£¼ì œë¡œ ë®¤ì§ë¹„ë””ì˜¤ìš© ê°€ì‚¬ë¥¼ ì‘ì„±í•´ì¤˜.
        
        ì£¼ì œ: {theme}
        ì¥ë¥´: {genre}
        ë¶„ìœ„ê¸°: {mood}
        ê¸¸ì´: 2ë¶„ 30ì´ˆ ë‚´ì™¸
        
        [Verse 1], [Chorus] ë“± ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì¤˜.
        """
        
        # Gemini API í˜¸ì¶œ
        import anthropic
        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        lyrics = response.content[0].text
        
        # ì €ì¥
        lyrics_path = self.base_dir / '02_lyrics' / 'lyrics.txt'
        with open(lyrics_path, 'w', encoding='utf-8') as f:
            f.write(lyrics)
        
        print(f"âœ… ê°€ì‚¬ ì €ì¥: {lyrics_path}")
        return lyrics
    
    def step2_music_generation_guide(self):
        """Suno ìŒì•… ìƒì„± ê°€ì´ë“œ (ìˆ˜ë™)"""
        print("\nğŸµ STEP 2: Suno AIì—ì„œ ìŒì•… ìƒì„±")
        print("=" * 50)
        print("1. https://suno.ai ì ‘ì†")
        print("2. Custom Mode ì„ íƒ")
        print(f"3. {self.base_dir / '02_lyrics' / 'lyrics.txt'} íŒŒì¼ ë‚´ìš© ë¶™ì—¬ë„£ê¸°")
        print("4. 3-5ê³¡ ìƒì„±")
        print("5. ìµœì ì˜ ê³¡ ì„ ì • í›„ ë‹¤ìš´ë¡œë“œ")
        print(f"6. {self.base_dir / '03_music' / 'selected_song.mp3'}ë¡œ ì €ì¥")
        print("=" * 50)
        input("ì™„ë£Œ í›„ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    async def step3_create_storyboard(self, lyrics: str, song_path: str):
        """ì½˜í‹° ìƒì„±"""
        print("\nğŸ¬ STEP 3: ì½˜í‹° ìƒì„± ì¤‘...")
        
        # ë…¸ë˜ ë¶„ì„
        song_data = analyze_song(song_path)
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì• ë‹ˆë©”ì´ì…˜ ë®¤ì§ë¹„ë””ì˜¤ ê°ë…ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì •ë³´ë¡œ ìƒì„¸í•œ ì½˜í‹°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        
        ë…¸ë˜ BPM: {song_data['bpm']}
        ë…¸ë˜ ê¸¸ì´: {song_data['duration']}ì´ˆ
        
        ê°€ì‚¬:
        {lyrics}
        
        30-50ê°œì˜ ì»·ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”. ê° ì»·ë§ˆë‹¤:
        - shot_number, timestamp_start, timestamp_end
        - lyrics_line, scene_description
        - shot_type (CU/MS/LS), camera_movement
        - character_action, mood, visual_style
        
        JSON ìŠ¤í‚¤ë§ˆ:
        {{
          "title": "string",
          "total_duration": number,
          "shots": [
            {{
              "shot_number": number,
              "timestamp_start": number,
              "timestamp_end": number,
              "lyrics_line": "string",
              "scene_description": "string",
              "shot_type": "CU" | "MS" | "LS",
              "camera_movement": "static" | "pan" | "zoom",
              "character_action": "string",
              "mood": "string",
              "visual_style": "string"
            }}
          ]
        }}
        """
        
        # Gemini í˜¸ì¶œ
        import anthropic
        client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        
        response = client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=8000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        # JSON íŒŒì‹±
        import json
        storyboard_text = response.content[0].text
        # ```json íƒœê·¸ ì œê±°
        storyboard_text = storyboard_text.replace('```json', '').replace('```', '').strip()
        storyboard_json = json.loads(storyboard_text)
        
        # ì €ì¥
        storyboard_path = self.base_dir / '04_storyboard' / 'storyboard.json'
        with open(storyboard_path, 'w', encoding='utf-8') as f:
            json.dump(storyboard_json, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ì½˜í‹° ì €ì¥: {storyboard_path}")
        return storyboard_json
    
    def step4_generate_niji_prompts(self, storyboard: dict, character_ref: str):
        """Nijijourney í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        print("\nğŸ¨ STEP 4: Nijijourney í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        
        prompts = []
        for shot in storyboard['shots']:
            prompt = generate_niji_prompt_from_shot(shot, character_ref)
            prompts.append({
                'shot_number': shot['shot_number'],
                'prompt': prompt
            })
        
        # ì €ì¥
        prompts_path = self.base_dir / '04_storyboard' / 'niji_prompts.json'
        with open(prompts_path, 'w', encoding='utf-8') as f:
            json.dump(prompts, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompts_path}")
        print("\nğŸ–¼ï¸ Nijijourney ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œì‘í•˜ì„¸ìš”:")
        print("   Discordì—ì„œ ê° í”„ë¡¬í”„íŠ¸ë¥¼ /imagineìœ¼ë¡œ ì…ë ¥")
        print(f"   ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ {self.base_dir / '05_images'}ì— ì €ì¥")
        
        return prompts
    
    async def step5_convert_to_videos(self, storyboard: dict):
        """ì´ë¯¸ì§€ë¥¼ ë™ì˜ìƒìœ¼ë¡œ ë³€í™˜"""
        print("\nğŸï¸ STEP 5: ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜ ì¤‘...")
        
        tasks = []
        for shot in storyboard['shots']:
            shot_num = shot['shot_number']
            image_path = self.base_dir / '05_images' / f"shot_{shot_num:03d}.png"
            output_path = self.base_dir / '06_videos' / f"clip_{shot_num:03d}.mp4"
            
            if not image_path.exists():
                print(f"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {image_path}")
                continue
            
            duration = shot['timestamp_end'] - shot['timestamp_start']
            task = image_to_video_replicate(
                str(image_path),
                str(output_path),
                shot['character_action'],
                int(duration)
            )
            tasks.append(task)
        
        # ë³‘ë ¬ ì²˜ë¦¬
        await asyncio.gather(*tasks)
        print("âœ… ëª¨ë“  í´ë¦½ ë³€í™˜ ì™„ë£Œ")
    
    def step6_final_edit(self, storyboard: dict, music_path: str):
        """ìµœì¢… í¸ì§‘"""
        print("\nâœ‚ï¸ STEP 6: ìµœì¢… í¸ì§‘ ì¤‘...")
        
        # Concat íŒŒì¼ ìƒì„±
        concat_path = self.base_dir / 'concat_list.txt'
        create_video_concat_file_from_dict(storyboard, str(concat_path))
        
        # FFmpeg ê²°í•©
        output_path = self.base_dir / '07_final' / 'music_video_final.mp4'
        subprocess.run([
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', str(concat_path),
            '-i', music_path,
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '192k',
            '-shortest',
            str(output_path)
        ])
        
        print(f"âœ… ìµœì¢… ì˜ìƒ: {output_path}")
        return output_path

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
async def main():
    # í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
    pipeline = MusicVideoPipeline("my_first_mv")
    
    # STEP 1: ê°€ì‚¬ ìƒì„±
    lyrics = await pipeline.step1_generate_lyrics(
        theme="ê¿ˆì„ í–¥í•´ ë‚ ì•„ê°€ëŠ” ì†Œë…€",
        genre="J-pop",
        mood="í¬ë§ì ì´ê³  ë°ì€"
    )
    
    # STEP 2: Suno ìŒì•… ìƒì„± (ìˆ˜ë™)
    pipeline.step2_music_generation_guide()
    
    # STEP 3: ì½˜í‹° ìƒì„±
    storyboard = await pipeline.step3_create_storyboard(
        lyrics,
        "music-video-project/my_first_mv/03_music/selected_song.mp3"
    )
    
    # STEP 4: Nijijourney í”„ë¡¬í”„íŠ¸
    prompts = pipeline.step4_generate_niji_prompts(
        storyboard,
        character_ref="https://s.mj.run/YOUR_CHAR_REF"
    )
    
    print("\nâ¸ï¸ Nijijourneyì—ì„œ ì´ë¯¸ì§€ ìƒì„± í›„ ê³„ì†í•˜ë ¤ë©´ Enter")
    input()
    
    # STEP 5: ë™ì˜ìƒ ë³€í™˜
    await pipeline.step5_convert_to_videos(storyboard)
    
    # STEP 6: ìµœì¢… í¸ì§‘
    final_video = pipeline.step6_final_edit(
        storyboard,
        "music-video-project/my_first_mv/03_music/selected_song.mp3"
    )
    
    print("\nğŸ‰ ë®¤ì§ë¹„ë””ì˜¤ ì œì‘ ì™„ë£Œ!")
    print(f"ê²°ê³¼ë¬¼: {final_video}")

if __name__ == '__main__':
    asyncio.run(main())
```

---

## í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì½˜í‹° ë‹¨ê³„
- [ ] ëª¨ë“  ê°€ì‚¬ êµ¬ê°„ì´ ì‹œê°í™”ë˜ì—ˆëŠ”ê°€?
- [ ] íƒ€ì´ë°ì´ ë…¸ë˜ ê¸¸ì´ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] ê°ì • ì „í™˜ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
- [ ] ìƒ· íƒ€ì…ì´ ë‹¤ì–‘í•˜ê²Œ ë°°ì¹˜ë˜ì—ˆëŠ”ê°€? (CU/MS/LS ê· í˜•)

### ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„
- [ ] ìºë¦­í„° ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
- [ ] ë°°ê²½ ìŠ¤íƒ€ì¼ì´ í†µì¼ë˜ì–´ ìˆëŠ”ê°€?
- [ ] í•´ìƒë„ê°€ ì¶©ë¶„í•œê°€? (ìµœì†Œ 1920x1080)
- [ ] ì½˜í‹°ì˜ scene_descriptionê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?

### ë™ì˜ìƒ ë³€í™˜ ë‹¨ê³„
- [ ] ëª¨ì…˜ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€? (ê³¼ë„í•œ ì›Œí•‘ ì—†ìŒ)
- [ ] í”„ë ˆì„ë ˆì´íŠ¸ê°€ ì¼ì •í•œê°€? (24fps)
- [ ] í™”ì§ˆ ì €í•˜ê°€ ì—†ëŠ”ê°€?
- [ ] ìºë¦­í„° ì–¼êµ´/ëˆˆì´ ì œëŒ€ë¡œ ë³´ì´ëŠ”ê°€?

### ìµœì¢… í¸ì§‘ ë‹¨ê³„
- [ ] ì˜¤ë””ì˜¤ì™€ ì˜ìƒ ì‹±í¬ê°€ ì •í™•í•œê°€?
- [ ] íŠ¸ëœì§€ì…˜ì´ ì–´ìƒ‰í•˜ì§€ ì•Šì€ê°€?
- [ ] ìƒ‰ë³´ì •ì´ ì¼ê´€ë˜ê²Œ ì ìš©ë˜ì—ˆëŠ”ê°€?
- [ ] ì „ì²´ íë¦„ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
- [ ] ë Œë”ë§ ì—ëŸ¬ê°€ ì—†ëŠ”ê°€?

---

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ë¬¸ì œ 1: Nijijourney ìºë¦­í„° ì¼ê´€ì„± ë¶€ì¡±

**ì¦ìƒ**: ìƒ·ë§ˆë‹¤ ìºë¦­í„° ì–¼êµ´ì´ ë‹¤ë¦„

**í•´ê²°**:
```
1. Character Reference ì´ë¯¸ì§€ë¥¼ ë” ê°•í•˜ê²Œ ì ìš©
   --cref URL --cw 100 (weight ìµœëŒ€)

2. í”„ë¡¬í”„íŠ¸ì—ì„œ ë³€í•˜ì§€ ì•Šì„ íŠ¹ì§• ëª…ì‹œ
   "girl with long brown hair and blue eyes" (ë§¤ í”„ë¡¬í”„íŠ¸)

3. Style Referenceë„ í•¨ê»˜ ì‚¬ìš©
   --sref URL --sw 50

4. ê·¹ë‹¨ì  ê°ë„ëŠ” í”¼í•˜ê¸°
   CU, MS ìœ„ì£¼ë¡œ êµ¬ì„±í•˜ê³  LSëŠ” ìµœì†Œí™”
```

### ë¬¸ì œ 2: Image-to-Video ëª¨ì…˜ì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€

**ì¦ìƒ**: ìºë¦­í„°ê°€ ë…¹ì•„ë‚´ë¦¼, ì–¼êµ´ ì™œê³¡

**í•´ê²°**:
```python
# Replicate APIì˜ motion_bucket_id ì¡°ì •
# ë‚®ì„ìˆ˜ë¡ ëª¨ì…˜ ì ìŒ (ì•ˆì •ì ), ë†’ì„ìˆ˜ë¡ ì—­ë™ì  (ë¶ˆì•ˆì •)

# ì •ì ì¸ ì”¬ (ì–¼êµ´ í´ë¡œì¦ˆì—…)
motion_bucket_id = 50

# ì¤‘ê°„ (ê±·ê¸°, ëŒì•„ë³´ê¸°)
motion_bucket_id = 100

# ì—­ë™ì  (ë›°ê¸°, ì¶¤)
motion_bucket_id = 180
```

**ëŒ€ì•ˆ**: 
- ì¤‘ìš” ì”¬ì€ Veo 3 ì‚¬ìš© (í’ˆì§ˆ ìµœìš°ì„ )
- ComfyUI + ControlNetìœ¼ë¡œ í”„ë ˆì„ë³„ ì œì–´

### ë¬¸ì œ 3: ë…¸ë˜ì™€ ì˜ìƒ ê¸¸ì´ ë¶ˆì¼ì¹˜

**ì¦ìƒ**: ì˜ìƒì´ ë…¸ë˜ë³´ë‹¤ ê¸¸ê±°ë‚˜ ì§§ìŒ

**í•´ê²°**:
```python
def sync_video_to_audio(video_path: str, audio_path: str, output_path: str):
    """
    ì˜ìƒì„ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ì •í™•íˆ ë§ì¶¤
    """
    # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¶”ì¶œ
    probe = ffmpeg.probe(audio_path)
    audio_duration = float(probe['format']['duration'])
    
    # ì˜ìƒ ì†ë„ ì¡°ì •
    subprocess.run([
        'ffmpeg', '-i', video_path,
        '-i', audio_path,
        '-filter:v', f"setpts={audio_duration}/duration*PTS",
        '-map', '0:v', '-map', '1:a',
        '-c:v', 'libx264', '-c:a', 'aac',
        output_path
    ])
```

### ë¬¸ì œ 4: Replicate API Rate Limit

**ì¦ìƒ**: Too many requests ì—ëŸ¬

**í•´ê²°**:
```python
import time
from functools import wraps

def rate_limit(calls_per_minute=10):
    """Rate limiter ë°ì½”ë ˆì´í„°"""
    min_interval = 60.0 / calls_per_minute
    last_called = [0.0]
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            wait_time = min_interval - elapsed
            if wait_time > 0:
                time.sleep(wait_time)
            result = func(*args, **kwargs)
            last_called[0] = time.time()
            return result
        return wrapper
    return decorator

@rate_limit(calls_per_minute=5)
def safe_replicate_call(image_path, output_path):
    return image_to_video_replicate(image_path, output_path)
```

### ë¬¸ì œ 5: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**: ë Œë”ë§ ì¤‘ í”„ë¡œê·¸ë¨ í¬ë˜ì‹œ

**í•´ê²°**:
```python
# ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
def process_in_batches(shots, batch_size=5):
    """
    í•œ ë²ˆì— 5ê°œì”©ë§Œ ì²˜ë¦¬
    """
    for i in range(0, len(shots), batch_size):
        batch = shots[i:i+batch_size]
        for shot in batch:
            process_shot(shot)
        
        # ë°°ì¹˜ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        import gc
        gc.collect()
        time.sleep(10)
```

---

## ê³ ê¸‰ íŒ

### 1. ìë§‰ ì¶”ê°€

```python
def add_subtitles(video_path: str, storyboard: dict, output_path: str):
    """
    ê°€ì‚¬ ìë§‰ì„ ì˜ìƒì— ì¶”ê°€
    """
    # SRT íŒŒì¼ ìƒì„±
    srt_content = ""
    for i, shot in enumerate(storyboard['shots'], 1):
        start_time = format_srt_time(shot['timestamp_start'])
        end_time = format_srt_time(shot['timestamp_end'])
        lyrics = shot['lyrics_line']
        
        srt_content += f"{i}\n{start_time} --> {end_time}\n{lyrics}\n\n"
    
    srt_path = 'subtitles.srt'
    with open(srt_path, 'w', encoding='utf-8') as f:
        f.write(srt_content)
    
    # FFmpegë¡œ ìë§‰ ë²ˆ
    subprocess.run([
        'ffmpeg', '-i', video_path,
        '-vf', f"subtitles={srt_path}:force_style='FontName=Arial,FontSize=24,PrimaryColour=&HFFFFFF&,OutlineColour=&H000000&,Outline=2'",
        '-c:a', 'copy',
        output_path
    ])
```

### 2. ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€

```python
def create_intro_outro(title: str, artist: str):
    """
    íƒ€ì´í‹€ ì¹´ë“œ ìƒì„±
    """
    from PIL import Image, ImageDraw, ImageFont
    
    # 1920x1080 ë¹ˆ ì´ë¯¸ì§€
    img = Image.new('RGB', (1920, 1080), color='black')
    draw = ImageDraw.Draw(img)
    
    # í°íŠ¸ (ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ)
    font_title = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 72)
    font_artist = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 48)
    
    # í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬
    title_bbox = draw.textbbox((0, 0), title, font=font_title)
    title_width = title_bbox[2] - title_bbox[0]
    draw.text(((1920 - title_width) / 2, 400), title, fill='white', font=font_title)
    
    artist_bbox = draw.textbbox((0, 0), artist, font=font_artist)
    artist_width = artist_bbox[2] - artist_bbox[0]
    draw.text(((1920 - artist_width) / 2, 550), artist, fill='gray', font=font_artist)
    
    # ì €ì¥
    img.save('intro_card.png')
    
    # 5ì´ˆ ì •ì  ì˜ìƒ ìƒì„±
    subprocess.run([
        'ffmpeg',
        '-loop', '1',
        '-i', 'intro_card.png',
        '-c:v', 'libx264',
        '-t', '5',
        '-pix_fmt', 'yuv420p',
        'intro.mp4'
    ])
```

### 3. íš¨ê³¼ìŒ ì¶”ê°€

```python
def add_sound_effects(video_path: str, sfx_list: list, output_path: str):
    """
    íŠ¹ì • íƒ€ì´ë°ì— íš¨ê³¼ìŒ ì¶”ê°€
    
    sfx_list = [
        {'file': 'whoosh.mp3', 'time': 10.5, 'volume': 0.5},
        {'file': 'impact.mp3', 'time': 25.0, 'volume': 0.8}
    ]
    """
    # FFmpeg filter_complex êµ¬ì„±
    filter_parts = []
    for i, sfx in enumerate(sfx_list):
        filter_parts.append(f"[{i+1}:a]adelay={int(sfx['time']*1000)}|{int(sfx['time']*1000)},volume={sfx['volume']}[a{i}]")
    
    # ëª¨ë“  ì˜¤ë””ì˜¤ ë¯¹ì‹±
    amix_inputs = "[0:a]" + "".join([f"[a{i}]" for i in range(len(sfx_list))])
    filter_parts.append(f"{amix_inputs}amix=inputs={len(sfx_list)+1}:duration=longest[aout]")
    
    filter_complex = ";".join(filter_parts)
    
    # FFmpeg ì‹¤í–‰
    cmd = ['ffmpeg', '-i', video_path]
    for sfx in sfx_list:
        cmd.extend(['-i', sfx['file']])
    cmd.extend([
        '-filter_complex', filter_complex,
        '-map', '0:v', '-map', '[aout]',
        '-c:v', 'copy', '-c:a', 'aac',
        output_path
    ])
    
    subprocess.run(cmd)
```

---

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ì¶”ì²œ í•™ìŠµ ìë£Œ
- **Nijijourney ê°€ì´ë“œ**: https://docs.midjourney.com/docs/niji-model
- **FFmpeg íŠœí† ë¦¬ì–¼**: https://ffmpeg.org/documentation.html
- **DaVinci Resolve ë¬´ë£Œ ê°•ì˜**: YouTube "DaVinci Resolve Beginners"
- **AnimateDiff ê°€ì´ë“œ**: GitHub AnimateDiff repository

### ì»¤ë®¤ë‹ˆí‹°
- **Reddit r/StableDiffusion**: Image-to-Video ê¸°ë²• ê³µìœ 
- **Discord Midjourney**: Nijijourney ì»¤ë®¤ë‹ˆí‹°
- **GitHub Awesome AI Video**: AI ì˜ìƒ ë„êµ¬ ëª¨ìŒ

### ëŒ€ì•ˆ ë„êµ¬
| ë‹¨ê³„ | ì›ë˜ ë„êµ¬ | ëŒ€ì•ˆ |
|------|----------|-----|
| ê°€ì‚¬ ìƒì„± | Gemini | ChatGPT, Claude |
| ìŒì•… ìƒì„± | Suno | Udio, MusicGen |
| ì´ë¯¸ì§€ ìƒì„± | Nijijourney | Stable Diffusion + LoRA |
| I2V ë³€í™˜ | Veo 3, Replicate | Runway Gen-3, Pika |
| í¸ì§‘ | DaVinci Resolve | Premiere Pro, Final Cut |

---

## ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì œì‘ ì‹œì‘ ì „:
- [ ] ëª¨ë“  AI ì„œë¹„ìŠ¤ êµ¬ë… í™•ì¸
- [ ] API Key ë°œê¸‰ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
- [ ] FFmpeg ì„¤ì¹˜ í™•ì¸ (`ffmpeg -version`)
- [ ] Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±

ì œì‘ ì™„ë£Œ í›„:
- [ ] ìµœì¢… ì˜ìƒ í’ˆì§ˆ ì²´í¬ (1080p ì´ìƒ)
- [ ] ì˜¤ë””ì˜¤ ì‹±í¬ í™•ì¸
- [ ] ìƒ‰ë³´ì • í†µì¼ì„± í™•ì¸
- [ ] íŒŒì¼ ë°±ì—… (ì›ë³¸ ì´ë¯¸ì§€, ì¤‘ê°„ íŒŒì¼ ë³´ê´€)
- [ ] í¬íŠ¸í´ë¦¬ì˜¤ìš© ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜

---

## ë§ˆë¬´ë¦¬

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ ì•½ **6-8ì‹œê°„**ì´ë©´ ì²« ë®¤ì§ë¹„ë””ì˜¤ë¥¼ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì„±ê³µ ìš”ì†Œ**:
1. **ì½˜í‹°ë¥¼ ì •êµí•˜ê²Œ** - ì „ì²´ í’ˆì§ˆì˜ 70%ê°€ ì—¬ê¸°ì„œ ê²°ì •ë¨
2. **Character Reference ì²« ì´ë¯¸ì§€ë¥¼ ì‹ ì¤‘íˆ** - ì¼ê´€ì„±ì˜ ê¸°ì´ˆ
3. **íƒ€ì´ë° ì •í™•íˆ** - ë…¸ë˜ì™€ ì˜ìƒì´ 1í”„ë ˆì„ë„ ì–´ê¸‹ë‚˜ì§€ ì•Šê²Œ
4. **ì ì§„ì  ê°œì„ ** - ì²« ì‘í’ˆì€ í•™ìŠµ ëª©ì , ë‘ ë²ˆì§¸ë¶€í„° ë³¸ê²©í™”

**ê°œì„  ë¡œë“œë§µ**:
- 1ì°¨ ì œì‘: ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìŠµë“
- 2ì°¨ ì œì‘: ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ë„ì… (30% ì‹œê°„ ë‹¨ì¶•)
- 3ì°¨ ì œì‘: ê³ ê¸‰ ì´í™íŠ¸ ì¶”ê°€ (ìƒ‰ë³´ì •, íš¨ê³¼ìŒ)
- 4ì°¨ ì œì‘: ComfyUI ë„ì…ìœ¼ë¡œ í’ˆì§ˆ ê·¹ëŒ€í™”

ë§‰íˆëŠ” ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“  ì§ˆë¬¸í•˜ì„¸ìš”. íŒŒì´íŒ…! ğŸ¬âœ¨
